group = "condition"
)
runApp()
missing_channels <- panel_data$fcs_colname[!panel_data$fcs_colname %in% colnames(samp)]
print(missing_channels)
runApp()
# 去除 panel_data 中的 Width 通道
panel_data <- panel_data[panel_data$fcs_colname != "Width", ]
sce <- prepData(
samp,
panel = panel_data,
md = meta_data,
transform = TRUE,
features = panel_data$fcs_colname,
md_cols = list(
file = "file_name",
id = "sample_id",
group = "condition"
)
# 这三个是user data
mass_fcs_zip_path <- "D:\\Downloads\\dataset1\\fcs_data.zip"
mass_meta_data_path <- "D:\\Downloads\\dataset1\\sample_metadata.xlsx"
mass_data_path <- "D:\\Downloads\\dataset1\\panel_metadata.xlsx"
meta_data <- read_excel(mass_meta_data_path)
panel_data <- read_excel(mass_data_path)
head(meta_data)
head(panel_data)
# 查看 panel_data 中的通道名称
print(panel_data$fcs_colname)
# 去除 panel_data 中的 Width 通道
panel_data <- panel_data[panel_data$fcs_colname != "Width", ]
head(panel_data)
# 查看 panel_data 中的通道名称
print(panel_data$fcs_colname)
# 去除 panel_data 中的 Width 通道
panel_data <- panel_data[panel_data$fcs_colname != "Width", ]
# 查看 samp 中的列名
print(colnames(samp))
temp_dir <- tempdir()
unlink(temp_dir, recursive = TRUE)  # 清理目录中的所有文件和子目录
dir.create(temp_dir)  # 重新创建临时目录
unzip(zipfile = mass_fcs_zip_path, exdir = temp_dir, junkpaths = TRUE)
fcs_files <- list.files(temp_dir, pattern = ".fcs$", full.names = TRUE)
samp <- read.flowSet(files = fcs_files)
# warnings()
sce <- prepData(
samp,
panel = panel_data,
md = meta_data,
transform = TRUE,
features = panel_data$fcs_colname,
md_cols = list(
file = "file_name",
id = "sample_id",
group = "condition"
)
runApp()
# 这三个是user data
mass_fcs_zip_path <- "D:\\Downloads\\dataset1\\fcs_data.zip"
mass_meta_data_path <- "D:\\Downloads\\dataset1\\sample_metadata.xlsx"
mass_data_path <- "D:\\Downloads\\dataset1\\panel_metadata.xlsx"
meta_data <- read_excel(mass_meta_data_path)
panel_data <- read_excel(mass_data_path)
head(meta_data)
head(panel_data)
# 查看 panel_data 中的通道名称
print(panel_data$fcs_colname)
# 去除 panel_data 中的 Width 通道
panel_data <- panel_data[panel_data$fcs_colname != "Width", ]
# 查看 samp 中的列名
print(colnames(samp))
temp_dir <- tempdir()
unlink(temp_dir, recursive = TRUE)  # 清理目录中的所有文件和子目录
dir.create(temp_dir)  # 重新创建临时目录
unzip(zipfile = mass_fcs_zip_path, exdir = temp_dir, junkpaths = TRUE)
fcs_files <- list.files(temp_dir, pattern = ".fcs$", full.names = TRUE)
samp <- read.flowSet(files = fcs_files)
# 查看 meta_data 中的文件名
print(meta_data$file_name)
# 查看 samp 中的文件名
print(sampleNames(samp))  # 使用 flowSet 或 flowFrame 的函数查看样本名称
runApp()
meta_data$file_name <- gsub("\\.fcs$", "_clean.fcs", meta_data$file_name)
# 查看 meta_data 中的文件名
print(meta_data$file_name)
# 查看 samp 中的文件名
print(sampleNames(samp))  # 使用 flowSet 或 flowFrame 的函数查看样本名称
# warnings()
sce <- prepData(
samp,
panel = panel_data,
md = meta_data,
transform = TRUE,
features = panel_data$fcs_colname,
md_cols = list(
file = "file_name",
id = "sample_id",
group = "condition"
)
# 这三个是user data
mass_fcs_zip_path <- "D:\\Downloads\\dataset1\\fcs_data.zip"
mass_meta_data_path <- "D:\\Downloads\\dataset1\\sample_metadata.xlsx"
mass_data_path <- "D:\\Downloads\\dataset1\\panel_metadata.xlsx"
meta_data <- read_excel(mass_meta_data_path)
panel_data <- read_excel(mass_data_path)
head(meta_data)
head(panel_data)
# 查看 panel_data 中的通道名称
print(panel_data$fcs_colname)
# 去除 panel_data 中的 Width 通道
panel_data <- panel_data[panel_data$fcs_colname != "Width", ]
# 查看 samp 中的列名
print(colnames(samp))
temp_dir <- tempdir()
unlink(temp_dir, recursive = TRUE)  # 清理目录中的所有文件和子目录
dir.create(temp_dir)  # 重新创建临时目录
unzip(zipfile = mass_fcs_zip_path, exdir = temp_dir, junkpaths = TRUE)
fcs_files <- list.files(temp_dir, pattern = ".fcs$", full.names = TRUE)
samp <- read.flowSet(files = fcs_files)
meta_data$file_name <- gsub("\\.fcs$", "_clean.fcs", meta_data$file_name)
# 查看 meta_data 中的文件名
print(meta_data$file_name)
# 查看 samp 中的文件名
print(sampleNames(samp))  # 使用 flowSet 或 flowFrame 的函数查看样本名称
# warnings()
sce <- prepData(
samp,
panel = panel_data,
md = meta_data,
transform = TRUE,
features = panel_data$fcs_colname,
md_cols = list(
file = "file_name",
id = "sample_id",
group = "condition"
)
runApp()
colnames(colData(cptac))
########################################################################################
peptide_file <- "D:\\Downloads\\peptidesRaw_PDAC_Coverage_PIF50_mrri10.txt"
peptide_data <- read.delim(peptide_file,sep = "\t", header = TRUE)
head(peptide_data)
anyNA(colnames(peptide_data))
meta_file <- "D:\\Downloads\\new-PDAC_Coverage_SampleGuide.csv"
meta_data <- read.csv(meta_file,sep = ",",header = TRUE)
head(meta_data)
# 确定 ecol 的范围，基于列数
ecol <- 3:ncol(peptide_data)
# 使用 readQFeatures 读取数据
cptac <- readQFeatures(peptide_data, quantCols = ecol, name = "peptides", fnames = "peptide")
cptac
colnames(colData(cptac))
if (!"peptide_counts" %in% colnames(colData(cptac))) {
cptac <- countUniqueFeatures(cptac, i = "peptides", colDataName = "peptide_counts")
cptac <- countUniqueFeatures(cptac, i = "peptides", groupBy = "protein", colDataName = "protein_counts")
}
colnames(colData(cptac))
selected_method <- "median"
cptac <- aggregateFeatures(cptac, i = "peptides", fcol = "protein", name = "proteins_colMedians", fun = colMedians)
colnames(colData(cptac))
# 第[3]个 assay
name <- "proteins_colMedians"
cptac <- sweep(cptac, i = name, MARGIN = 2, FUN = "-",
STATS = colMedians(assay(cptac[[name]]), na.rm = TRUE),
name = paste0(name, "_norm_col"))
colnames(colData(cptac))
# Center rows with mean ## Normalization
new_name = paste0(name, "_norm_col")
new_name2 = paste0(name, "_norm")
# 第[4]个 assay
cptac <- sweep(cptac, i = new_name, MARGIN = 1, FUN = "-",
STATS = rowMeans(assay(cptac[[new_name]]), na.rm = TRUE),
name = paste0(name, "_norm"))
assay(cptac[[new_name]]) <- assay(cptac[[new_name2]])
print("check here, how many col names in cptac:")
print(cptac)
print(names(cptac))
# 把最后一个名字改成 proteins_colMedians_norm_imputed
names(cptac)[4] <- paste0(new_name2, "_imputed")
print(names(cptac))
cptac <- impute(cptac, i = paste0(new_name2, "_imputed"),
method = "knn", k = 3, rowmax = 1, colmax = 1,
maxp = Inf, rng.seed = 1234)
# Step 8: Batch correction
colData(cptac)
# 动态添加 batch_label 和 celltype 到 colData(cptac)
colData(cptac) <- cbind(
colData(cptac),
batchlabel = meta_data[, selected_field, drop = T],
celltype = meta_data[, "celltype", drop = T]
)
selected_field <- "lcbatch"
# 动态添加 batch_label 和 celltype 到 colData(cptac)
colData(cptac) <- cbind(
colData(cptac),
batchlabel = meta_data[, selected_field, drop = T],
celltype = meta_data[, "celltype", drop = T]
)
colData(cptac)
cptac_sub <- getWithColData(cptac, paste0(name, "_norm_imputed"))
batch <- colData(cptac_sub)$batchlabel
model <- model.matrix(~ celltype, data = colData(cptac_sub))
assay(cptac_sub) <- ComBat(dat = assay(cptac_sub),
batch = batch,
mod = model)
table(batch)
table(colData(cptac_sub)$celltype)
table(batch, colData(cptac_sub)$celltype)
valid_rows <- !is.na(batch) & !is.na(colData(cptac_sub)$celltype)
cptac_sub <- cptac_sub[, valid_rows]
batch <- colData(cptac_sub)$batchlabel
model <- model.matrix(~ celltype, data = colData(cptac_sub))
anyNA(assay(cptac_sub))
sum(is.na(assay(cptac_sub)))
assay(cptac_sub) <- ComBat(dat = assay(cptac_sub),
batch = batch,
mod = model)
model <- model.matrix(~ 1, data = colData(cptac_sub))  # 不包含 celltype
assay(cptac_sub) <- ComBat(dat = assay(cptac_sub),
batch = batch,
mod = model)
###############################################################################
# 检查协变量分布
table(batch)
table(colData(cptac_sub)$celltype)
table(batch, colData(cptac_sub)$celltype)
# 移除不平衡的批次或协变量水平
valid_rows <- !is.na(batch) & !is.na(colData(cptac_sub)$celltype)
cptac_sub <- cptac_sub[, valid_rows]
batch <- colData(cptac_sub)$batchlabel
model <- model.matrix(~ celltype, data = colData(cptac_sub))
# 简化模型矩阵（如果需要）
if (any(is.na(model))) {
warning("Simplifying model matrix due to singularity issues.")
model <- model.matrix(~ 1, data = colData(cptac_sub))  # 仅保留批次信息
}
# 检查缺失值
if (anyNA(assay(cptac_sub))) {
warning("Missing values detected. Consider imputing missing values.")
}
# 执行 ComBat 批次效应校正
assay(cptac_sub) <- ComBat(dat = assay(cptac_sub),
batch = batch,
mod = model)
head(peptide_data)
# 移除 peptide_data 中完全为空的列
empty_cols <- sapply(peptide_data, function(x) all(is.na(x)))
empty_cols
head(peptide_data)
runApp()
??unzip()
runApp()
shiny::runApp()
BiocManager::install("impute")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library("Seurat")
??FindVariableFeatures()
runApp()
runApp()
runApp()
runApp()
peptide_file <- "./data/3.mass_example_data/disrupted_peptide_level_data_pep_cell_0.5_6.txt"
# 读取肽段数据
peptide_data <- read.delim(peptide_file, sep = "\t", fileEncoding = "UTF-8")
peptide_data[1:5,1:5]
# 检查是否有 NA 列名
if (anyNA(colnames(peptide_data))) {
stop("Peptide data 文件中存在 NA 列名，请确保所有列名都是有效的。")
}
# 移除 peptide_data 中完全为空的列
empty_cols <- sapply(peptide_data, function(x) all(is.na(x)))
if (any(empty_cols)) {
warning("Peptide data 中存在完全为空的列，这些列将被删除。")
peptide_data <- peptide_data[, !empty_cols]
}
dim(peptide_data)
dim(peptide_data)
# 清理列名，确保其合法且唯一
colnames(peptide_data) <- make.names(colnames(peptide_data), unique = TRUE)
dim(peptide_data)
# 确定 ecol 的范围，基于列数
ecol <- 3:ncol(peptide_data)
# 使用 readQFeatures 读取数据
cptac <- readQFeatures(peptide_data, quantCols = ecol, name = "peptides", fnames = "peptide")
selected_method <- "median"
cptac <- zeroIsNA(data, i = seq_along(data))
library(QFeatures)
library(scp)
library(sva)
cptac <- zeroIsNA(data, i = seq_along(data))
??zeroIsNA()
library(QFeatures)
cptac <- zeroIsNA(data, i = seq_along(data))
cptac <- zeroIsNA(cptac, i = seq_along(cptac))
nNA(cptac, i = seq_along(cptac)) # Record results for later analysis if needed
cptac <- filterNA(cptac, i = seq_along(cptac), pNA = 0.99)
dim(cptac)
cptac
colnames(colData(cptac))
if (!"peptide_counts" %in% colnames(colData(cptac))) {
cptac <- countUniqueFeatures(cptac, i = "peptides", colDataName = "peptide_counts")
cptac <- countUniqueFeatures(cptac, i = "peptides", groupBy = "protein", colDataName = "protein_counts")
}
colnames(colData(cptac))
names(cptac)
colData(cptac)
if (selected_method == "sum") {
cptac <- aggregateFeatures(cptac, i = "peptides", fcol = "protein", name = "proteins_colSums", fun = colSums)
name = "proteins_colSums"
} else if (selected_method == "mean") {
cptac <- aggregateFeatures(cptac, i = "peptides", fcol = "protein", name = "proteins_colMeans", fun = colMeans)
name = "proteins_colMeans"
} else if (selected_method == "median") {
cptac <- aggregateFeatures(cptac, i = "peptides", fcol = "protein", name = "proteins_colMedians", fun = colMedians)
name = "proteins_colMedians"
} else if (selected_method == "medianPolish") {
cptac <- aggregateFeatures(cptac, i = "peptides", fcol = "protein", name = "proteins_medianPolish", fun = MsCoreUtils::medianPolish)
name = "proteins_medianPolish"
}
name
# # 第[3]个 assay
cptac <- sweep(cptac, i = name, MARGIN = 2, FUN = "-",
STATS = colMedians(assay(cptac[[name]]), na.rm = TRUE),
name = paste0(name, "_norm_col"))
# Center rows with mean ## Normalization
new_name = paste0(name, "_norm_col")
new_name2 = paste0(name, "_norm")
# 第[4]个 assay
cptac <- sweep(cptac, i = new_name, MARGIN = 1, FUN = "-",
STATS = rowMeans(assay(cptac[[new_name]]), na.rm = TRUE),
name = paste0(name, "_norm"))
assay(cptac[[new_name]]) <- assay(cptac[[new_name2]])
print("check here, how many col names in cptac:")
print(cptac)
print(names(cptac))
# 把最后一个名字改成 proteins_colMedians_norm_imputed
names(cptac)[4] <- paste0(names(cptac)[4], "_imputed")
# names(cptac)[4] <- paste0(new_name2, "_imputed")
# names(cptac)[5] <- "proteins_colMedians_norm"
print("after change names:")
print(names(cptac))
# Impute missing values using k-nearest neighbors (kNN)
cptac <- impute(cptac, i = paste0(new_name2, "_imputed"),
method = "knn", k = 3, rowmax = 1, colmax = 1,
maxp = Inf, rng.seed = 1234)
print(names(cptac))
usename <- paste0(name, "_norm_imputed_batchC")
usename
if (!usename %in% names(cptac)) {
usename <- paste0(name, "_norm_imputed")
}
print("usename:")
print(usename)
data_matrix <- assay(cptac[[usename]])
if (anyNA(data_matrix) || any(is.infinite(data_matrix))) {
stop("Data matrix contains NA or Inf values. Please clean your data.")
}
# data_matrix <- as(data_matrix, "dgCMatrix")
data_matrix[1:5,1:5]
# 创建 Seurat 对象
seurat_obj <- CreateSeuratObject(counts = data_matrix, project = "Protein_Analysis", min.cells = 1, min.features = 10)
seurat_obj
# 标准化和变量特征选择
seurat_obj <- NormalizeData(seurat_obj)
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = "vst", nfeatures = 2000)
new_name2
cptac
# 创建 Seurat 对象
seurat_obj <- CreateSeuratObject(counts = data_matrix, project = "Protein_Analysis")
seurat_obj
# 标准化和变量特征选择
seurat_obj <- NormalizeData(seurat_obj)
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = "vst", nfeatures = 2000)
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = "vst", nfeatures = 1000)
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = "vst", nfeatures = 100)
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = "vst", nfeatures = 5000)
seurat_obj@assays
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = "vst")
names(cptac)
data_matrix <- assay(cptac[["imputedAssay"]])
data_matrix <- as(data_matrix, "dgCMatrix")
data_matrix[1:5,1:5]
# 创建 Seurat 对象
seurat_obj <- CreateSeuratObject(counts = data_matrix, project = "Protein_Analysis")
seurat_obj@assays
# 标准化和变量特征选择
seurat_obj <- NormalizeData(seurat_obj)
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = "vst")
variable_features <- VariableFeatures(seurat_obj)
if (length(variable_features) == 0) {
stop("No variable features identified. Check your data.")
}
dim(data_matrix)
names(cptac)
data_matrix <- assay(cptac[["proteins_colMedians_norm_col"]])
data_matrix <- as(data_matrix, "dgCMatrix")
data_matrix[1:5,1:5]
dim(data_matrix)
data_matrix <- assay(cptac[["proteins_colMedians"]])
data_matrix <- as(data_matrix, "dgCMatrix")
data_matrix[1:5,1:5]
dim(data_matrix)
# 标准化和变量特征选择
# seurat_obj <- NormalizeData(seurat_obj)
# seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = "vst")
# variable_features <- VariableFeatures(seurat_obj)
# if (length(variable_features) == 0) {
#   stop("No variable features identified. Check your data.")
# }
seurat_obj[["protein"]] <- CreateAssayObject(data = data_matrix)
# Use all features or select variable features with an appropriate method
VariableFeatures(seurat_obj) <- rownames(data_matrix)
# Scale data
seurat_obj <- ScaleData(seurat_obj, features = rownames(data_matrix), assay = "protein")
# Run PCA
seurat_obj <- RunPCA(seurat_obj, features = rownames(data_matrix), assay = "protein", verbose = FALSE)
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(QFeatures)
library(scp)
library(sva)
peptide_file <- "./data/3.mass_example_data/disrupted_peptide_level_data_pep_cell_0.5_6.txt"
# 读取肽段数据
peptide_data <- read.delim(peptide_file, sep = "\t", fileEncoding = "UTF-8")
peptide_data[1:5,1:5]
dim(peptide_data)
# 检查是否有 NA 列名
if (anyNA(colnames(peptide_data))) {
stop("Peptide data 文件中存在 NA 列名，请确保所有列名都是有效的。")
}
# 移除 peptide_data 中完全为空的列
empty_cols <- sapply(peptide_data, function(x) all(is.na(x)))
if (any(empty_cols)) {
warning("Peptide data 中存在完全为空的列，这些列将被删除。")
peptide_data <- peptide_data[, !empty_cols]
}
dim(peptide_data)
# 清理列名，确保其合法且唯一
colnames(peptide_data) <- make.names(colnames(peptide_data), unique = TRUE)
colnames(peptide_data)
# 确定 ecol 的范围，基于列数
ecol <- 3:ncol(peptide_data)
# 使用 readQFeatures 读取数据
cptac <- readQFeatures(peptide_data, quantCols = ecol, name = "peptides", fnames = "peptide")
selected_method <- "median"
cptac <- zeroIsNA(cptac, i = seq_along(cptac))
nNA(cptac, i = seq_along(cptac)) # Record results for later analysis if needed
cptac <- filterNA(cptac, i = seq_along(cptac), pNA = 0.99)
cptac
if (!"peptide_counts" %in% colnames(colData(cptac))) {
cptac <- countUniqueFeatures(cptac, i = "peptides", colDataName = "peptide_counts")
cptac <- countUniqueFeatures(cptac, i = "peptides", groupBy = "protein", colDataName = "protein_counts")
}
names(cptac)
colData(cptac)
dim(colData(cptac))
metadata_data <- read.csv("./data/3.mass_example_data/scope2_batchlabel.csv")
head(metadata_data)
dim(metadata_data)
# bind
colData(cptac) <- cbind(colData(cptac), metadata_data)
colData(cptac)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
shiny::runApp()
runApp()
rsconnect::deployApp()
BiocManager::version()
BiocManager::install(version = "3.19")
BiocManager::install("rhdf5", version = "3.19")
BiocManager::install("rhdf5", version = "3.19", force = T)
renv::snapshot(force = TRUE)
rsconnect::deployApp()
shiny::runApp()
runApp()
rsconnect::deployApp()
runApp()
shiny::runApp()
